 <!DOCTYPE html>

<html><head>
<title>Peng Zhang - Shandong University of Science and Technology</title>

<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>

<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


	body
	{
	font-family:"Roboto",Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;font-weight:300;
    	background-color : #CDCDCD;
	}
    	.content
	{
    		width : 900px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 850px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 820px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #1367a7;
		height: 158px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

	#sdst_logo {
		position: absolute;
		left: 560px;
		top: 14px;
		width: 20px;
		height: 20px;
	}
	#uts_logo {
        position: absolute;
        left: 646px;
        top: 14px;
        width: 100px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
	height:120px;
        width: 160px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }
    .media {
	outline: thin dotted #666666;
 	margin-bottom: 15px;	
	margin-left:10px;
    }
    .media-body {
	margin-top:5px;
	padding-left:20px;
    }

.papers-selected h5, .papers-selected h4 { display : none; }
.papers-selected .publication { display : none; }
.paperhi-only { display : none; }
.papers-selected .paperhi { display : flex; }
.papers-selected .paperlo { display : none; }

.hidden>div {
	display:none;
}

.visible>div {
	display:block;
}
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-23931362-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-23931362-2');
</script>

<script type="text/javascript">
    var myPix = new Array("imgs/profile.jpeg","imgs/profile.jpeg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };
</script>

<script>
$(document).ready(function() {
  $('.paperlo button').click(function() {
     $('.papers-container').addClass('papers-selected');
  });
  $('.paperhi button').click(function() {
     $('.papers-container').removeClass('papers-selected');
  });
  $('.papers-container').removeClass('papers-selected');

		$('.text_container').addClass("hidden");

		$('.text_container').click(function() {
			var $this = $(this);

			if ($this.hasClass("hidden")) {
				$(this).removeClass("hidden").addClass("visible");

			} else {
				$(this).removeClass("visible").addClass("hidden");
			}
		});

});
</script>

</head>


<body>
<div class="content">
	<div id="container">

	<table>
	<tbody><tr>
	<td><img id="myPicture" src="imgs/profile.jpeg" style="float:left; padding-right:20px" width="200px" height="200px"></td>
	<script>choosePic();</script>
	<td>
	<div id="DocInfo">
		<h1>Peng Zhang</h1>
		Ph.D, Lecturer<br>
		Department of Artificial Intelligence,<br>
		Shandong University of Science and Technology <br>
        Office: J13-322, 579 Qianwangang Road, Qingdao, 266590 <br>
		Email: <a href="pengzhang.sdu@gmail.com">pengzhang.sdu [at] gmail.com</a><br>
        <a href="CV_web.pdf">CV</a> &bull; <a href="https://scholar.google.com/citations?user=inYJJjoAAAAJ&hl=en">Google Scholar</a> &bull; <a href="https://github.com/pzhang0610">Github</a>&bull; <a href="http://cise.sdust.edu.cn/home/Page/dep_detail/catId/73/id/824.html">主页</a> <br>
	</div><br>
  
     <div id="sdst_logo">
        <img src="imgs/sdst.jpg"  width="80" height="80"/></a>
	</div>

    <div id="uts_logo">
        <img src="imgs/uts_logo.png" width="160" height="80"/>
	</div>

	</td>
	</tr>
	</tbody></table>
	<br>

	<h2>About Me</h2>
	<ul>
	Greetings! I am a lecturer in <a href="https://en.sdust.edu.cn">Shandong University of Science and Technology (SDUST)</a>. I received my PhD degree from <a href="https://www.uts.edu.au">University of Technology Sydney (UTS)</a> supervised by A/Prof. <a href="https://www.uts.edu.au/staff/qiang.wu">Qiang Wu</a> and Dr. <a href="https://www.uts.edu.au/staff/jingsong.xu">Jingsong Xu</a> in Aug. 2020.
			Before that, I received B.E. and M.E. from <a href="http://www.en.sdu.edu.cn">Shandong University</a> supervised by Prof. <a href="https://scholar.google.com/citations?hl=en&user=dyGlWmkAAAAJ">Xianye Ben</a> in 2013 and 2016, respectively. Besides, 
			I am a visiting student at <a href="http://en.xjtu.edu.cn/index.htm">Xi'an Jiaotong University</a> during Aug. 2010 - Jul. 2011. My research interest includes gait recognition, 
			person re-identification and generative adversarial networks, etc.
	</ul>

	<!--
	<h2>Research</h2>
    <ul>
        <li>Computer Vision, Machine Learning, Gait recognition, Person re-identification, GAN</li> 

    </ul>
	-->
    <h2>News</h2>
    <ul>
		<li> [2022/04/28] 1 paper is accepted to IEEE Trans. MM.</li>
		<li>[2022/02/28] CFP: We organized a special issue named "视频监控下的身份识别技术" on <a href="https://mp.weixin.qq.com/s/vmZrMAJPAVF_1vzWVY6Dgw">《中国图象图形学报》</a></li>
		<li>[2022/02/28] CFP: We organize a special issue named "Computational Intelligence in Image Processing and Pattern Recognition" on <a href="https://www.mdpi.com/journal/mathematics/special_issues/Intelligence_Image_Processing_Pattern_Recognition">mathmetics</a></li>
		<li>[2022/02/28] CFP: We organize a special issue named "Deep Learning for Facial Expression Analysis" on <a href="https://www.mdpi.com/journal/applsci/special_issues/Facial_Expression_Analysis">applied sciences </a></li>
		    <li>[2021/06/14] I am invited as a reviewer for ICLR 2022. </li>
		    <li>[2021/06/02] I am invited as the publicity co-chair for <a href="http://icigp.org/">ICIGP 2022</a>. Welcome to submit your research outputs to ICIGP 2022.</li>
		    <li>[2021/05/19] I am invited as a reviewer for VCIP 2021 and NeurIPS 2021.</li> 
		    <li>[2021/05/14] I launch a speech in Anqing Normal University. </li>
		    <li>[2021/03/15] 1 paper is accepted to IEEE Trans. MM. </li>
		    <li>[2021/01/31] 1 paper is accepted to Image and Vision Computing. </li>
    </ul>


 <h2>Academic Services</h2>
	<div>
    <ul>
        <li>Conference reviewer for
			<ul>
				<li>35th Conference on Neural Information Processing Systems (NeurIPS 2021)
				<li>International Conference on Multimedia and Expo (ICME), 2021, 2020</li>
				<li>International Conference on Learning Representations (ICLR),2022, 2021</li>
				<li>International Conference on Machine Learning (ICML), 2022, 2020</li> 
				<li>International Conference on Visual Communication and Image Processing (VCIP),2022, 2020, 2019</li>
				<li>International Conference on Machine Learning and Data Science (ICMLDS), 2019,2018</li>
			</ul>
		</li>
	    <li>Journal reviewer for 
			<ul>
				<li>IEEE Transactions on Image Processing</li>
				<li>IEEE Transactions on Multimedia </li>
				<li>IEEE Transactions on Circuits and Systems for Video Technology </li>
				<li>IEEE Signal Processing Letters</li> 
				<li>IEEE Journal of Biomedical and Health Informatics</li> 
				<li>Neurocomputing</li>
				<li>Optik</li> 
				<li> Frontiers of Information Technology Electronic Engineering</li>
				<li>Peej Computer Science</li>
				<li>吉林大学学报(工学版)</li>
				<li>Image and Vision Computing</li>
			</ul>
		</li>
		<!--		<li>Assistant reviewer for ECCV2020, CVPR 2020, AAAI 2020, ICCV 2019, VCIP 2018, ICME 2017, ICIP 2017, AVSS 2017, DICTA 2017</li> /-->
		<li>Volunteer for VCIP 2019, ICML 2017</li>
    </ul>        
</div>

	<h2>Teaching</h2>
		<ul>
			<li> Machine Learning Theory, PhD Class 2020</li>
			<li> Machine Learning, On-job Postgraduate Class 2021</li>
		</ul>

	<h2> Project</h2>
		<ul>
			<li> Elite Talent Program of SDUST, 2020.11-2025.11</li>
			<li>Natural Science Foundation of Shandong Province for Younth, 2022.01-2024.12</li>
		</ul>
<div class="text_container">		
    <h2>Honors</h2>
	<div>
        <ul>
			<li> UTS Industry Scholarship, 2016--2020</li>
			<li> UTS International Research Scholarship, 2016--2020</li>
			<li> Excellent Thesis Award of Shandong Unversity, 2017</li>
			<li> Outstanding Graduate of Shandong Province, 2016 </li>
			<li> National Scholarship, 2015 & 2014 </li>
        </ul>    
	</div>
</div>

<div class="papers-container papers-selected"> 
	<h5 class="paperlo">All Publications<button type="button" class="ml-3 btn btn-light"> Show selected</button></h5>
	<h5 class="paperhi paperhi-only">Selected Publications<button type="button" class="ml-3 btn btn-light"> Show all</button></h5>

	<h5 class="pt-2 pb-1">Journals</h5>
	
	<div class="publication media">
		<img src="imgs/tmm_improvedGait.jpg" class="papericon">
		<div class="media-body"><b>Improving Disentangled Representation Learning for Gait Recognition using Group Supervision.</b><br>
			Lingxiang Yao, Worapan Kusakunniran, <b>Peng Zhang</b>, Qiang Wu, Jian Zhang.<br><i>IEEE Transactions on Multimedia, 2021.</i><br>
			[<a href="https://ieeexplore.ieee.org/document/9767609">PDF</a>]
	</div></div>

	<div class="publication media">
           <img src="imgs/alleviating.png" class="papericon">
           <div class="media-body"><b>Alleviating Modality Bias Training for Infrared-Visible Person Re-identification.</b><br>
			  Yan Huang, Qiang Wu, Jingsong Xu, Yi Zhong, <b>Peng Zhang</b>, Zhaoxiang Zhang.<br><i>IEEE Transactions on Multimedia, 2021, Early Access.</i><br>[<a href="https://doi.org/10.1109/TMM.2021.3067760">PDF</a>]
	</div></div>

	<div class="publication media paperhi">
           <img src="imgs/beyond_dapr.png" class="papericon">
           <div class="media-body"><b>Beyond Madality Alignment: Learning Part-level representation for Visible-infrared Person Re-identification.</b><br>
			   <b>Peng Zhang</b>, Qiang Wu, Xunxiang Yao, Jingsong Xu.<br><i>Image and Vision Computing, 2021, Early Access.</i><br>[<a href="https://doi.org/10.1016/j.imavis.2021.104118">PDF</a>]
	</div></div>

	<div class="publication media paperhi">
           <img src="imgs/learning_st.png" class="papericon">
           <div class="media-body"><b>Learning Spatial-temporal Representations over Walking Tracklet for Long-term Person Re-Identification in The Wild.</b><br>
			   <b>Peng Zhang</b>, Jingsong Xu, Qiang Wu, Yan Huang, Xianye Ben.<br><i>IEEE Transactions on Multimedia, 2020, Early Access.</i><br>[<a href="https://ieeexplore.ieee.org/abstract/document/9214519">PDF</a>]
	</div></div>

	<div class="publication media">
           <img src="imgs/super_res.jpg" class="papericon">
           <div class="media-body"><b>Weighted Adaptive Image Super-Resolution Scheme based on Local Fractal Feature and Image Roughness.</b><br>
			   Xunxiang Yao, Qiang Wu, <b>Peng Zhang</b>, Fangxun Bao.<br><i>IEEE Transactions on Multimedia, 2020, Early Access.</i><br>[<a href="https://ieeexplore.ieee.org/abstract/document/9099392">PDF</a>]
	</div></div>
	
	<div class="publication media">
           <img src="imgs/beyond.jpg" class="papericon">
           <div class="media-body"><b>Beyond Scalar Neuron: Adopting Vector-Neuron Capsules for Long-Term Person Re-Identification.</b><br>
			   Yan Huang, Jingsong Xu, Qiang Wu, Yi Zhong, <b>Peng Zhang</b>, Zhaoxiang Zhang.<br><i>IEEE Transactions on Circuits and Systems for Video Technology, 2019, Early Access.</i><br>[<a href="https://ieeexplore.ieee.org/document/8873614">PDF</a>]
	</div></div>
	
	<div class="publication media paperhi">
           <img src="imgs/top_push.png" class="papericon">
           <div class="media-body"><b>Top-Push Constrained Modality-Adaptive Dictionary Learning for Cross-Modality Person Re-Identification.</b><br>
			   <b>Peng Zhang</b>, Jingsong Xu, Qiang Wu, Yan Huang, Jian Zhang.<br><i>IEEE Transactions on Circuits and Systems for Video Technology, 2019, Early Access.</i><br>[<a href="https://ieeexplore.ieee.org/document/8825984">PDF</a>]
	</div></div>

	<div class="publication media paperhi">
		<img src="imgs/tensor_gait.png" class="papericon">
		<div class="media-body"><b>A General Tensor Representation Framework for Cross-view Gait Recognition.</b><br>
			Xianye Ben, <b>Peng Zhang</b>, Zhihui Lai, Rui Yan, Xinliang Zhai, Weixiao Meng.<br><i>Pattern Recognition, 2019.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320319300251">PDF</a>]
	</div></div>

	<div class="publication media">
		<img src="imgs/cpa.jpg" class="papericon">
		<div class="media-body"><b>Coupled Patch Alignment for Matching Cross-View Gaits.</b><br>
			Xianye Ben, Chen Gong, <b>Peng Zhang</b>, Xitong Jia, Qiang Wu, Weixiao Meng.<br><i>IEEE Transactions on Image Processing, 2019.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/8624554">PDF</a>]
	</div></div>

	<div class="publication media">
		<img src="imgs/cbdp.jpg" class="papericon">
		<div class="media-body"><b>Coupled Bilinear Discriminant Projection for Cross-view Gait Recognition.</b><br>
			Xianye Ben, Chen Gong, <b>Peng Zhang</b>, Rui Yan, Qiang Wu, Weixiao Meng.<br><i>IEEE Transactions on Circuits and Systems for Video Technology, 2019.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/8616800">PDF</a>]
		</div></div>
    
	<div class="publication media">
		<img src="imgs/ivc_adaptive.jpg" class="papericon">
		<div class="media-body"><b>Adaptive Rational Fractal Interpolation Function for Image Super-resolution via Local Fractal Analysis.</b><br>
			Xunxiang Yao, Qiang Wu, <b>Peng Zhang</b>, Fangxun Bao.<br><i>Image and Vision Computing, 2019.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/pii/S0262885619300101">PDF</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/nca_gait.jpg" class="papericon">
		<div class="media-body"><b>Gait Recognition  And  Micro-expression Recognition Based on Maximum Margin Projection with Tensor Representation.</b><br>
			Xianye Ben, <b>Peng Zhang</b>, Rui Yan, Mingqiang Yang, Guodong Ge.<br><i>Neural Computing and Applications, 2016.</i><br>
			[<a href="https://link.springer.com/article/10.1007/s00521-015-2031-8">PDF</a>]
	</div></div>	
	
	<div class="publication media">
		<img src="imgs/neuro_gait.jpg" class="papericon">
		<div class="media-body"><b>On The Distance Metric Learning Between Cross-domain Gaits.</b><br>
			Xianye Ben, <b>Peng Zhang</b>, Weixiao Meng, Rui Yan, Mingqiang Yang, Wenhe Liu, Hui Zhang.<br><i>Neurocomputing, 2016.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/pii/S0925231216304672">PDF</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/optik_micro.jpg" class="papericon">
		<div class="media-body"><b>Micro-expression Recognition System.</b><br>
			<b>Peng Zhang</b>, Xianye Ben, Rui Yan, Chen Wu, Chang Guo.<br><i>Optik, 2016.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/pii/S0030402615016009">PDF</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/optik_coupled.jpg" class="papericon">
		<div class="media-body"><b>Coupled Marginal Discriminant Mappings for Low-resolution Face Recognition.</b><br>
			<b>Peng Zhang</b>, Xianye Ben, Wei Jiang, Rui Yan, Yiming Zhang.<br><i>Optik, 2015.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/pii/S0030402615008992">PDF</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/optik_ortho.jpg" class="papericon">
		<div class="media-body"><b>Orthogonal Multilinear Discriminant Analysis And Its Subblock Tensor Analysis Version.</b><br>
			Xianye Ben, Mingyan Jiang, Rui Yan, Weixiao Meng, <b>Peng Zhang</b>.<br><i>Optik, 2015.</i><br>
			[<a href="https://www.sciencedirect.com/science/article/pii/S0030402614011292">PDF</a>]
		</div></div>

	<!--   
	<div class="publication media paperhi"> 
           <img src="imgs/gan.gif" class="papericon">
           <div class="media-body">
			<strong>Temporal Relational Reasoning in Videos.</strong><br>
           <u>Bolei Zhou</u>, Alex Andonian, Aude Oliva, and Antonio Torralba<br>European Conference on Computer Vision (ECCV), 2018.<br>[<a href="publication/eccv18-TRN.pdf">PDF</a>][<a href="https://arxiv.org/pdf/1711.08496.pdf">arXiv</a>][<a href="http://relation.csail.mit.edu">Webpage</a>][<a href="https://www.youtube.com/watch?v=D42erLb42_k">Demo Video</a>][<a
               href="https://github.com/metalbubble/TRN-pytorch">Code</a>][<a href="http://news.mit.edu/2018/machine-learning-video-activity-recognition-0914">MIT News</a>]
	</div></div>
	-->
	<h5 class="pt-2 pb-1">Conferences</h5>
	<div class="publication media paperhi">
		<img src="imgs/ijcnn_vtgan.jpg" class="papericon">
		<div class="media-body"><b>VT-GAN: View Transformation GAN for Gait Recognition Across View.</b><br>
			<b>Peng Zhang</b>, Qiang Wu, Jingsong Xu.<br><i>The International Joint Conference on Neural Network(IJCNN), 2019, Oral.</i><br>		
			[<a href="https://ieeexplore.ieee.org/document/8852258">PDF</a>][<a href="">PPT</a>]
		</div></div>
	
	<div class="publication media paperhi">
		<img src="imgs/ijcnn_vngan.jpg" class="papericon">
		<div class="media-body"><b>VN-GAN: Identity-preserved Variation Normalizing GAN for Gait Recognition.</b><br>
			<b>Peng Zhang</b>, Qiang Wu, Jingsong Xu.<br><i>The International Joint Conference on Neural Network(IJCNN), 2019.</i><br>		
			[<a href="https://ieeexplore.ieee.org/document/8852401">PDF</a>][<a href="">Poster</a>]
		</div></div>

	<div class="publication media paperhi">
		<img src="imgs/wacv_long.jpg" class="papericon">
		<div class="media-body"><b>Long-term Person Re-identification Using True Motion from Videos</b><br>
			<b>Peng Zhang</b>, Qiang Wu, Jingsong Xu, Jian Zhang.<br><i>IEEE Winter Conference on Applications of Computer Vision (WACV), 2018.</i><br>		
			[<a href="https://ieeexplore.ieee.org/abstract/document/8354164">PDF</a>][<a href="https://youtu.be/ZGZ-pMfdOz0">Oral</a>][<a href="">PPT</a>][<a href="">Poster</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/i2mtc_virtual.jpg" class="papericon">
		<div class="media-body"><b>A Virtual Instrument for Diagnosis to Substation Grounding Grids in Harsh Electromagnetic Environment.</b><br>
			Hengli Song, Haobin Dong, <b>Peng Zhang</b>.<br><i>IEEE International Instrumentation And Measurement Tchnology Conference (I2MTC), 2017.</i><br>		
			[<a href="https://ieeexplore.ieee.org/abstract/document/7969925">PDF</a>]
		</div></div>

	<div class="publication media">
		<img src="imgs/ccdc_multilinear.jpg" class="papericon">
		<div class="media-body"><b>Multilinear Mean Component Analysis for Gait Recognition.</b><br>
			Yawei Tian, Xianye Ben, <b>Peng Zhang</b>.<br><i>The 26th Chinese Control and Decision Conference (CCDC), 2014.</i><br>		
			[<a href="https://ieeexplore.ieee.org/abstract/document/7969925">PDF</a>]
		</div></div>
	
	<!--
	<h2>Teaching</h2>
		<ul>
			<li> Machine Learning Theory, PhD Class 2020</li>
			<li> Machine Learning, On-job Postgraduate Class 2021</li>
		</ul>

	<h2> Project</h2>
		<ul>
			<li> Elite Talent Program of SDUST, 2020.11-2025.11</li>
			<li>Natural Science Foundation of Shandong Province for Younth, 2022.01-2024.12</li>
		</ul>
	-->
		<!--
<div class="text_container">
    <h2>Talks</h2>
	<div>
    <ul>
        <li><a href="ppt/presentation_ICML_workshop.pdf">Interpreting Deep Visual Representations</a> at <a href="http://icmlviz.github.io/">Workshop on Visualization for Deep Learning</a>, ICML'17, Sydney.</li>
        <li><a href="ppt/presentation_CVPR17_oraltalk.pdf">Network Dissection: Quantifying the Interpretability of Deep Visual Representations</a>, CVPR'17, Hawaii.</li>
        <li><a href="http://deeplearning.csail.mit.edu/">Tutorial on the Deep Learning for Objects and Scenes</a>, CVPR'17, Hawaii.</li>
        <li><a href="ppt/understandCNN_tufts.pdf">Understand and Leverage the Internal Representations of CNNs</a> at Tufts, Cornell Tech, Harvard. </li>
        <li><a href="publication/scene_challenges2016.pdf">Challenges in Deep Sceen Understanding</a> at ECCV'16 ILSVRC and COCO joint workshop, Oct. 2016, Amsterdam.</li> 
        <li><a href="http://places.csail.mit.edu/slide_iclr2015.pdf">Object Detectors Emerge in Deep Scene CNNs</a> at ICLR'15, May 2015, San Diego.</li>
        <li><a href="">Learning Deep Features for Scene Recognition</a> at NIPS'14, Dec. 2014, Montreal.</li>
        <li><a href="http://mmlab.ie.cuhk.edu.hk/projects/collectiveness/presentation_cvpr2013.pdf">Measuring Crowd Collectiveness</a> at CVPR'13, June 2013, Portland.</li>
        <li><a href="http://mmlab.ie.cuhk.edu.hk/projects/dynamicagent/presentation_ppt.pdf">Understanding Crowd Behaviors</a> at CVPR'12, June 2012, Rhode Island.</li>
    </ul>
	</div>
</div>
-->
<!--
<div class="text_container">
    <h2>Media coverage</h2>
	<div>
    <ul>
        <li><a href="https://venturebeat.com/2018/09/14/mit-csail-designs-ai-that-can-track-objects-over-time/">VentureBeat</a>: MIT CSAIL designs AI that can track objects over time.</li>
        <li><a href="http://news.mit.edu/2018/machine-learning-video-activity-recognition-0914">MIT News</a>: Helping computers fill in the gaps between video frames.</li>
        <li><a href="https://qz.com/1022156/mit-researchers-can-now-track-artificial-intelligences-decisions-back-to-single-neurons/">Quartz</a>: Track AI decisions back to single neurons.</li>
        <li><a href="http://news.mit.edu/2017/inner-workings-neural-networks-visual-data-0630">MIT News</a>: Peering into neural networks.</li>
        <li><a href="https://techcrunch.com/2017/06/30/mit-csail-research-offers-a-fully-automated-way-to-peer-inside-neural-nets/">TechCrunch</a>: A fully automated way to peer inside neural networks.</li>
        <li><a href="https://www.csail.mit.edu/csail_computer_vision_team_leads_scene_parsing_challenge%20">MIT CSAIL News</a>: Scene parsing and scene classification challenges.</li>
        <li><a href="http://techcrunch.com/2015/05/08/ai-project-designed-to-recognize-scenes-surprises-by-identifying-objects-too/" target="_blank">TechCrunch</a> and <a href="http://newsoffice.mit.edu/2015/visual-scenes-object-recognition-0508" target="_blank">MIT News</a>: Object detectors emerge in CNNs.</li>
    </ul>
	</div>
</div>
-->

<!--
<div class="text_container">		
    <h2>Honors</h2>
	<div>
        <ul>
			<li> UTS Industry Scholarship, 2016-2020</li>
			<li> UTS International Research Scholarship, 2016-2020</li>
			<li> Excellent Thesis Award of Shandong Unversity, 2017</li>
			<li> Outstanding Graduate of Shandong Province, 2016 </li>
			<li> National Scholarship, 2015 & 2014 </li>
        </ul>    
	</div>
</div>

<div class="text_container"> 
    <h2>Datasets & Benchmarks</h2>
	<div>	
    <ul>
		<li>TODO...</li>
    </ul>
	</div>
</div>

-->
<!--
    <h2>Collaborators</h2>
    <ul>
        <li>I am fortunate to work with these great people: <a href="http://cvcl.mit.edu/Aude.htm">Aude Oliva</a>(MIT), <a href="http://vision.princeton.edu/people/xj/">Jianxiong Xiao</a>(Princeton), <a href="http://www.cvc.uab.es/~agata/">Agata Lapedriza</a>(UOC), <a href="http://dusp.mit.edu/faculty/jinhua-zhao">Jinhua Zhao</a>(MIT), <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a>(CUHK), <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>(CUHK), <a href="http://ins.sjtu.edu.cn/faculty/zhanghepeng">Hepeng Zhang</a>(SJTU), <a href="http://bcmi.sjtu.edu.cn/~zhangliqing/">Liqing Zhang</a>(SJTU), <a href="http://www.houxiaodi.com/">Xiaodi Hou</a>(Caltech), <a href="http://liuliu.us/">Liu Liu</a>(MIT), <a href="http://people.csail.mit.edu/khosla/">Aditya Khosla (MIT)</a>, Robinson Piramuthu(eBay Research Labs), Vignesh Jagadeesh(eBay Research Labs), Yuandong Tian(FB), Rob Fergus(NYU&FB), Arthur Szlam(FB), Sainbayar
        Sukhbaatar(NYU), Zi Wang (MIT), Stefanie Jegelka (MIT), Hang Zhao (MIT), Xavier Puig (MIT), Sanja Fidler (UToronto), Larry Zitnick(FB).</li>
    </ul>
<div class="text_container">
    <h2>Personal interests</h2>
    <ul>
    <li>blogs:<a href="http://urbancomputation.wordpress.com/" target="_parent">Urban Computation</a>,<a href="https://crowdbehaviordotorg.wordpress.com/" target="_parent">Crowd Behavior &amp; Psychology</a></li>
    <li><a href="book.html">books</a>, <a href="image/beacon_hill.jpg">rock climbing (5.11C,V6)</a>, <a href="bolei_juggle.mp4">juggling</a> (recently), <a href="image/bass.jpg">bass player</a> (former <a href="image/i3.jpg">lead guitarist</a>)</a> </li>
    </ul>
</div>

   --> 

</div>
</div>
</body></html>

